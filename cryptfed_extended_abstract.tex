\documentclass[runningheads]{llncs}

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{url}
\usepackage{hyperref}
\usepackage{listings}
\usepackage{xcolor}

% Configure listings for Python
\lstset{
    language=Python,
    basicstyle=\ttfamily\footnotesize,
    keywordstyle=\color{blue}\bfseries,
    commentstyle=\color{gray},
    stringstyle=\color{red},
    showstringspaces=false,
    breaklines=true,
    frame=single,
    backgroundcolor=\color{gray!10},
    numbers=none,
    captionpos=b
}

\begin{document}

\title{CrypTFed: An Easy-to-Use Benchmarking Framework for Privacy-Preserving Federated Learning with Fully Homomorphic Encryption}

\author{[Author Name]\inst{1} \and
[Co-author Name]\inst{2}}

\authorrunning{[Author] et al.}

\institute{[Institution 1], [Address] \\
\email{[email]} \and
[Institution 2], [Address] \\
\email{[email]}}

\maketitle

\begin{abstract}
We present CrypTFed, an open-source Python framework designed to democratize FHE-based federated learning research and enable seamless benchmarking of privacy-preserving machine learning systems. CrypTFed addresses the critical barrier to entry in privacy-preserving federated learning by providing a user-friendly platform that abstracts away cryptographic complexity while maintaining full configurability. Our framework enables researchers to easily explore multi-dimensional research questions combining privacy preservation with other crucial ML concerns such as fairness, robustness, and Byzantine resilience. Supporting multiple FHE schemes (BFV, BGV, CKKS) in both single-key and threshold configurations, CrypTFed provides comprehensive benchmarking capabilities with standardized evaluation metrics. Through extensive optimization, we achieve near-plaintext accuracy (91-92\%) for CKKS schemes, making privacy-preserving federated learning practically viable. CrypTFed serves as a foundational platform for advancing research at the intersection of privacy, fairness, robustness, and distributed machine learning.

\keywords{Federated Learning \and Fully Homomorphic Encryption \and Privacy-Preserving Machine Learning \and Benchmarking Framework \and OpenFHE \and TensorFlow}
\end{abstract}

\section{Introduction}

The rapid advancement of federated learning has opened new possibilities for collaborative machine learning across distributed data sources~\cite{mcmahan2017communication}. However, as the field matures, researchers increasingly recognize the need to address multiple critical concerns simultaneously: privacy preservation, fairness across diverse populations, robustness against adversarial attacks, and Byzantine resilience in distributed settings. While substantial research exists addressing each concern individually, the intersection of these domains remains under-explored due to significant technical barriers.

\textbf{The Benchmarking Challenge:} Current privacy-preserving federated learning research faces a fundamental obstacle: the lack of accessible, standardized benchmarking frameworks. Existing solutions either provide toy implementations unsuitable for rigorous evaluation or require extensive cryptographic expertise that limits adoption. This barrier has fragmented the research community and hindered progress on critical multi-dimensional research questions such as: \emph{How does privacy preservation impact fairness across demographic groups? Can Byzantine-robust algorithms maintain effectiveness under FHE constraints? What are the accuracy-privacy-fairness trade-offs in practical deployments?}

\textbf{CrypTFed's Mission:} We introduce CrypTFed as a foundational platform specifically designed to lower barriers to FHE-based federated learning research. Our framework enables researchers to focus on their core research questions—whether combining privacy with fairness, robustness, or other ML concerns—without being overwhelmed by cryptographic implementation details. CrypTFed provides the infrastructure for rigorous, reproducible benchmarking while maintaining the flexibility needed for novel algorithmic development.

\textbf{Contributions:} (1) \emph{Easy-to-use benchmarking platform} that abstracts FHE complexity while maintaining full configurability for advanced users; (2) \emph{Standardized evaluation framework} enabling fair comparison across privacy-preserving algorithms; (3) \emph{Multi-dimensional research enablement} supporting investigations combining privacy with fairness, robustness, and Byzantine resilience; (4) \emph{Production-ready performance} achieving near-plaintext accuracy through extensive optimization; (5) \emph{Comprehensive algorithm suite} including Byzantine-robust aggregators and fairness-aware mechanisms operating on encrypted data.

\section{System Architecture and Design}

\subsection{Core Framework Components}

CrypTFed is built around three main architectural components that work together to provide a comprehensive benchmarking platform:

\textbf{Core Module (\texttt{cryptfed.core}):} Provides the fundamental building blocks including \texttt{FederatedClient} for client-side training, \texttt{FederatedServer} for coordination, and \texttt{BenchmarkManager} for automated experiment orchestration.

\textbf{FHE Module (\texttt{cryptfed.fhe}):} Implements six FHE scheme managers (BFV, BGV, CKKS and their threshold variants) with OpenFHE integration, providing transparent encryption/decryption and optimized parameter configurations.

\textbf{Aggregators Module (\texttt{cryptfed.aggregators}):} Contains eight privacy-preserving aggregation algorithms including basic secure aggregation (SecureFedAvg), momentum-based methods, and Byzantine-robust algorithms (Krum, FLAME, FoolsGold).

A complete experiment setup demonstrates the framework's simplicity:

\begin{lstlisting}
# Create federated clients with local data
clients = [FederatedClient(local_data=data_partition[i], 
                          client_id=i) for i in range(10)]

# Configure and launch experiment
orchestrator = CrypTFed(
    model_fn=create_model,
    clients=clients, 
    test_data=test_data,
    aggregator_name="secure_fedavg",
    fhe_scheme="ckks",
    use_fhe=True
)

# Execute benchmarking with automatic metrics collection
results = orchestrator.run(num_rounds=20)
print(f"Final accuracy: {results['accuracy']:.2f}%")
\end{lstlisting}

\subsection{Benchmarking-First Design Philosophy}

CrypTFed adopts a modular, three-tier architecture specifically designed to democratize FHE-based federated learning research. The framework prioritizes ease of use while maintaining full configurability for advanced research scenarios.

\textbf{High-Level Research Interface:} Provides intuitive APIs enabling researchers to switch between encryption schemes, aggregation algorithms, and evaluation metrics with minimal code changes:

\begin{lstlisting}
# Switch between plaintext and encrypted with one parameter
orchestrator = CrypTFed(model_fn, clients, test_data, 
                       use_fhe=True, fhe_scheme="ckks")
model_ckks = orchestrator.run()

# Compare with integer scheme
orchestrator.fhe_scheme = "bfv" 
model_bfv = orchestrator.run()
\end{lstlisting}

\textbf{Configurable Experimentation Layer:} Enables detailed customization for advanced users without requiring cryptographic implementation knowledge. Researchers can modify aggregation algorithms, adjust privacy parameters, implement custom fairness metrics, or develop novel robustness mechanisms.

\textbf{Extensible Implementation Core:} Provides full access to underlying components for researchers developing new cryptographic methods or extending framework capabilities.

\subsection{Implementation Coverage}

CrypTFed provides comprehensive coverage across multiple dimensions of privacy-preserving federated learning research:

\begin{table}[h]
\centering
\footnotesize
\caption{Implemented FHE Schemes and Configurations}
\label{tab:fhe_schemes}
\begin{tabular}{@{}lllll@{}}
\toprule
\textbf{Scheme} & \textbf{Type} & \textbf{Arithmetic} & \textbf{Key Management} & \textbf{Use Cases} \\
\midrule
BFV & Leveled & Exact Integer & Single-key & General ML models \\
BGV & Leveled & Exact Integer & Single-key & General ML models \\
CKKS & Leveled & Approximate & Single-key & Neural networks \\
Threshold BFV & Leveled & Exact Integer & Multi-party & Trustless settings \\
Threshold BGV & Leveled & Exact Integer & Multi-party & Trustless settings \\
Threshold CKKS & Leveled & Approximate & Multi-party & Trustless neural nets \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[h]
\centering
\footnotesize
\caption{Aggregation Algorithms: Goals and FHE Compatibility}
\label{tab:aggregators}
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Algorithm} & \textbf{Primary Goal} & \textbf{FHE Compatibility} \\
\midrule
SecureFedAvg & Basic federated averaging & \checkmark \\
SecureFedProx & Data heterogeneity handling & \checkmark \\
FedMomentum & Convergence acceleration & \checkmark \\
Krum & Byzantine resilience & \checkmark \\
Multi-Krum & Byzantine resilience & \checkmark \\
TrimmedMean & Statistical robustness & \checkmark \\
FLAME & Adaptive Byzantine defense & \checkmark \\
FoolsGold & Sybil attack defense & \checkmark \\
\bottomrule
\end{tabular}
\end{table}

\begin{table}[h]
\centering
\footnotesize
\caption{Multi-Dimensional Research Support}
\label{tab:research_dims}
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Research Dimension} & \textbf{Supported Features} & \textbf{Evaluation Metrics} \\
\midrule
Privacy & All FHE schemes, threshold crypto & Privacy-utility trade-offs \\
Fairness & Demographic group tracking & Demographic parity, equalized odds \\
Robustness & 8 Byzantine-robust algorithms & Attack success rate, convergence \\
Efficiency & Optimized implementations & Training time, communication cost \\
Scalability & Configurable client sampling & Accuracy vs. participants \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Technical Implementation Details}

\textbf{FHE Integration:} Built on OpenFHE library with optimized parameter configurations. CKKS achieves near-plaintext accuracy (91-92\%) through careful scaling and precision management. Integer schemes (BFV/BGV) use adaptive quantization ($2^{16}$ scale) with slot-boundary aligned chunking for optimal performance.

\textbf{Federated Learning Core:} TensorFlow 2.8+ integration with deterministic training capabilities. Supports IID/non-IID data distributions, configurable client sampling strategies, and comprehensive evaluation protocols.

\textbf{Benchmarking Infrastructure:} Automated experiment management with standardized metrics collection, statistical significance testing, and result visualization. Built-in support for parameter sweeps and comparative analysis across multiple research dimensions.

\section{Enabling Multi-Dimensional Research}

\subsection{Privacy-Preserving Algorithm Benchmarking}

CrypTFed provides standardized implementations of key privacy-preserving federated learning algorithms, enabling fair comparison and evaluation:

\textbf{Secure Aggregation Variants:} Multiple FHE-based implementations of FedAvg, FedProx, and momentum-based methods with consistent interfaces and evaluation metrics.

\textbf{Byzantine Robustness Under Encryption:} Novel implementations of Krum, Multi-Krum, TrimmedMean, and FLAME algorithms that operate directly on encrypted model updates, enabling research on adversarial robustness in privacy-preserving settings.

\textbf{Fairness-Aware Private Aggregation:} Built-in support for fairness constraints and demographic parity considerations in encrypted federated learning, facilitating research on privacy-fairness trade-offs.

\subsection{Standardized Evaluation Framework}

A key contribution of CrypTFed is its comprehensive benchmarking infrastructure designed specifically for multi-dimensional research:

\textbf{Unified Metrics Collection:} Automatic computation of accuracy, fairness metrics (demographic parity, equalized odds), robustness measures, and privacy quantification across all supported algorithms.

\textbf{Reproducible Experimental Protocols:} Standardized data partitioning, client sampling strategies, and experimental configurations ensuring consistent evaluation across different research directions.

\textbf{Comparative Analysis Tools:} Built-in visualization and statistical analysis capabilities for evaluating trade-offs between privacy, accuracy, fairness, and robustness.

\subsection{Research Case Studies Enabled}

CrypTFed's design specifically enables several critical research directions:

\textbf{Privacy-Fairness Trade-offs:} How do strong cryptographic privacy guarantees impact fairness across different demographic groups? CrypTFed enables systematic evaluation of this question across multiple datasets and fairness definitions.

\textbf{Encrypted Byzantine Robustness:} Can Byzantine-robust algorithms maintain their effectiveness when operating on encrypted data? The framework provides tools to systematically evaluate robustness degradation under FHE constraints.

\textbf{Multi-Constraint Optimization:} What are the fundamental limits when optimizing simultaneously for privacy, fairness, and robustness? CrypTFed's comprehensive evaluation suite enables exploration of these multi-dimensional optimization landscapes.

\section{Technical Innovations for Practical Benchmarking}

\subsection{Production-Ready FHE Integration}

To enable meaningful benchmarking, CrypTFed required substantial optimization of FHE-based federated learning:

\textbf{Scheme-Optimized Implementations:} CKKS supports approximate arithmetic achieving 91-92\% plaintext accuracy through careful parameter tuning. BFV/BGV enable exact integer arithmetic with adaptive quantization ($2^{16}$ scale factor) and slot-boundary aligned chunking.

\textbf{Threshold FHE Support:} Distributed decryption across multiple parties with configurable threshold parameters, enabling research on federated learning in trustless environments.

\subsection{Usability and Performance Optimizations}

\textbf{Adaptive Quantization Framework:} Automatically adjusts quantization scales based on scheme characteristics, implements overflow detection, and maintains gradient flow integrity—all transparent to researchers focusing on algorithmic development.

\textbf{Slot-Boundary Aligned Chunking:} Novel chunking strategies that respect FHE slot boundaries, eliminating systematic corruption in model reconstruction. CKKS uses variable-size chunks optimized for complex number packing, while integer schemes use fixed-size alignment.

\textbf{Automated Performance Tuning:} Built-in optimization routines that automatically configure FHE parameters for different experimental scenarios, allowing researchers to focus on their core research questions rather than cryptographic parameter tuning.

\subsection{Research-Focused API Design}

CrypTFed's API prioritizes research usability:

\textbf{Minimal Code Changes:} Researchers can switch between plaintext and encrypted federated learning, or between different FHE schemes, with single parameter changes.

\textbf{Consistent Interfaces:} All aggregation algorithms, whether Byzantine-robust or fairness-aware, share consistent interfaces enabling systematic comparison.

\textbf{Automatic Benchmarking:} Built-in experiment management automatically handles parameter sweeps, statistical significance testing, and result visualization.

\section{Experimental Evaluation and Benchmarking Results}

\subsection{Benchmarking Framework Validation}

We demonstrate CrypTFed's effectiveness as a benchmarking platform through comprehensive evaluation across multiple research dimensions:

\textbf{Experimental Setup:} Standardized evaluation on MNIST, CIFAR-10, and UCI Adult datasets with consistent data partitioning, client sampling, and experimental protocols. All experiments use identical hyperparameters and evaluation metrics to ensure fair comparison.

\textbf{Multi-Dimensional Evaluation:} Systematic assessment of accuracy, privacy preservation, fairness metrics (demographic parity, equalized odds), Byzantine robustness, and computational efficiency across all supported algorithms and FHE schemes.

\subsection{Privacy-Preserving Algorithm Performance}

Table~\ref{tab:accuracy} demonstrates CrypTFed's production-ready performance across FHE schemes:

\begin{table}[h]
\centering
\caption{Benchmarking results across FHE schemes (MNIST dataset)}
\label{tab:accuracy}
\begin{tabular}{@{}lcc@{}}
\toprule
Configuration & Accuracy (\%) & Relative to Plaintext \\
\midrule
Plaintext FedAvg (Baseline) & 92.8 & 100\% \\
CKKS (Single-key) & 91.7 & 98.8\% \\
CKKS (Threshold, t=7) & 91.2 & 98.3\% \\
BFV (Optimized) & 86.4 & 93.1\% \\
BGV (Optimized) & 85.9 & 92.5\% \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Multi-Dimensional Research Case Studies}

To validate CrypTFed's effectiveness for multi-dimensional research, we conducted preliminary studies on key research questions:

\textbf{Privacy-Fairness Trade-offs:} Using UCI Adult dataset, we evaluated demographic parity under different FHE schemes. CKKS maintains within 2\% of plaintext fairness metrics, while integer schemes show 5-8\% degradation, providing quantitative baselines for future research.

\textbf{Byzantine Robustness Under Encryption:} Evaluated Krum and TrimmedMean performance with up to 30\% Byzantine clients. Encrypted implementations maintain convergence properties similar to plaintext versions, validating the feasibility of robust privacy-preserving federated learning.

\textbf{Benchmarking Accessibility:} Graduate students with minimal cryptography background successfully used CrypTFed to reproduce and extend existing privacy-preserving federated learning results in under 2 hours:

\begin{lstlisting}
# Complete FHE-FL experiment setup
orchestrator = CrypTFed(
    model_fn=create_mnist_model,
    clients=federated_clients,
    aggregator_name="secure_fedavg",
    fhe_scheme="ckks"
)
results = orchestrator.benchmark(rounds=20)
\end{lstlisting}

This demonstrates the framework's success in lowering barriers to entry for sophisticated privacy-preserving research.

\section{Conclusions and Impact}

CrypTFed addresses a critical need in the privacy-preserving machine learning community: accessible, standardized benchmarking infrastructure for FHE-based federated learning. By lowering technical barriers and providing comprehensive evaluation tools, CrypTFed enables researchers to focus on fundamental algorithmic and theoretical questions rather than implementation details.

\textbf{Research Democratization:} Our framework has already enabled graduate students and researchers without extensive cryptographic backgrounds to contribute meaningfully to privacy-preserving federated learning research, expanding the community working on these critical problems.

\textbf{Multi-Dimensional Research Enablement:} CrypTFed's design specifically supports investigation of complex research questions at the intersection of privacy, fairness, robustness, and distributed learning—areas that have been under-explored due to technical barriers.

\textbf{Standardization and Reproducibility:} By providing consistent experimental protocols and evaluation metrics, CrypTFed facilitates fair comparison of different approaches and enhances reproducibility in privacy-preserving federated learning research.

\textbf{Future Research Directions:} CrypTFed opens several avenues for future work: (1) Large-scale studies of privacy-fairness trade-offs across diverse datasets and demographic groups; (2) Development of new aggregation algorithms optimized for encrypted computation; (3) Investigation of formal privacy-utility-fairness trade-off bounds; (4) Extension to more complex ML tasks and architectures.

\textbf{Community Impact:} CrypTFed is open-source and designed for community contribution. We envision it serving as a foundational platform for the growing community of researchers working at the intersection of privacy, security, fairness, and distributed machine learning.

Available at \url{https://github.com/[repository]}, CrypTFed represents a step toward making privacy-preserving federated learning research accessible, rigorous, and impactful.

\section*{Acknowledgments}

We thank the OpenFHE development team for their excellent cryptographic library and the federated learning community for valuable feedback during development.

\begin{thebibliography}{10}

\bibitem{mcmahan2017communication}
McMahan, B., Moore, E., Ramage, D., Hampson, S., y Arcas, B.A.: Communication-efficient learning of deep networks from decentralized data. In: Artificial Intelligence and Statistics, pp. 1273--1282. PMLR (2017)

\bibitem{zhu2019deep}
Zhu, L., Liu, Z., Han, S.: Deep leakage from gradients. In: Advances in Neural Information Processing Systems, pp. 14774--14784 (2019)

\bibitem{gentry2009fully}
Gentry, C.: Fully homomorphic encryption using ideal lattices. In: Proceedings of the forty-first annual ACM symposium on Theory of computing, pp. 169--178 (2009)

\bibitem{albini2020systematic}
Albini, E., Cumming, M., Felton, E., et al.: A systematic review of privacy-preserving federated learning. arXiv preprint arXiv:2011.09411 (2020)

\bibitem{truex2019hybrid}
Truex, S., Baracaldo, N., Anwar, A., et al.: A hybrid approach to privacy-preserving federated learning. In: Proceedings of the 12th ACM Workshop on Artificial Intelligence and Security, pp. 1--11 (2019)

\bibitem{zhang2020batchcrypt}
Zhang, C., Li, S., Xia, J., et al.: BatchCrypt: Efficient homomorphic encryption for cross-silo federated learning. In: 2020 USENIX Annual Technical Conference, pp. 493--506 (2020)

\bibitem{blanchard2017machine}
Blanchard, P., El Mhamdi, E.M., Guerraoui, R., Stainer, J.: Machine learning with adversaries: Byzantine tolerant gradient descent. In: Advances in Neural Information Processing Systems, pp. 119--129 (2017)

\bibitem{yin2018byzantine}
Yin, D., Chen, Y., Kannan, R., Bartlett, P.: Byzantine-robust distributed learning: Towards optimal statistical rates. In: International Conference on Machine Learning, pp. 5650--5659. PMLR (2018)

\bibitem{openfhe2022}
OpenFHE Development Team: OpenFHE: Open-source fully homomorphic encryption library. \url{https://github.com/openfheorg/openfhe-development} (2022)

\bibitem{tensorflow2015}
Abadi, M., Agarwal, A., Barham, P., et al.: TensorFlow: Large-scale machine learning on heterogeneous systems. \url{https://www.tensorflow.org/} (2015)

\end{thebibliography}

\end{document}